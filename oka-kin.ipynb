{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all package....\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Import Keras and other Deep Learning dependencies\n",
    "from keras.models import Sequential\n",
    "import time\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "import seaborn as sns\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import *\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "K.set_image_data_format('channels_last')\n",
    "import cv2\n",
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy.random as rng\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F0002/MID1</td>\n",
       "      <td>F0002/MID3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0002/MID2</td>\n",
       "      <td>F0002/MID3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F0005/MID1</td>\n",
       "      <td>F0005/MID2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F0005/MID3</td>\n",
       "      <td>F0005/MID2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F0009/MID1</td>\n",
       "      <td>F0009/MID4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p1          p2\n",
       "0  F0002/MID1  F0002/MID3\n",
       "1  F0002/MID2  F0002/MID3\n",
       "2  F0005/MID1  F0005/MID2\n",
       "3  F0005/MID3  F0005/MID2\n",
       "4  F0009/MID1  F0009/MID4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing train data...................\n",
    "\n",
    "train_data=pd.read_csv('train_relationships.csv')\n",
    "test_data=pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1    0\n",
       "p2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()\n",
    "train_data.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add non-related column.......\n",
    "list1=list(train_data.p1)\n",
    "\n",
    "list2=list(train_data.p2)\n",
    "new_list=list1[::-1]\n",
    "\n",
    "\n",
    "temp_data=pd.DataFrame({'p1':new_list,'p2':list2})\n",
    "#print(temp_data)\n",
    "train_data=pd.concat([train_data,temp_data])\n",
    "train_data.describe()\n",
    "\n",
    "#creating whole label................................................\n",
    "label=[]\n",
    "\n",
    "for i in range(0,7196):\n",
    "    if i<3599:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "#print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image_path(x):\n",
    "    image_path='train/'+x\n",
    "    temp_path='train/F0002/MID1/P00017_face3.jpg'\n",
    "    #print(image_path)\n",
    "    if os.path.exists(image_path):\n",
    "        #print(os.listdir(image_path)[0])\n",
    "        path=os.path.join(image_path,os.listdir(image_path)[0])\n",
    "        #print(path)\n",
    "        return path\n",
    "    else:\n",
    "        return temp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['p1_path']=train_data.p1.apply(lambda x:add_image_path(x))\n",
    "\n",
    "train_data['p2_path']=train_data.p2.apply(lambda x:add_image_path(x))\n",
    "\n",
    "\n",
    "train_data['is_related']=np.array(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p1_path</th>\n",
       "      <th>p2_path</th>\n",
       "      <th>is_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F0002/MID1</td>\n",
       "      <td>F0002/MID3</td>\n",
       "      <td>train/F0002/MID1/P00017_face3.jpg</td>\n",
       "      <td>train/F0002/MID3/P00013_face3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0002/MID2</td>\n",
       "      <td>F0002/MID3</td>\n",
       "      <td>train/F0002/MID2/P00018_face3.jpg</td>\n",
       "      <td>train/F0002/MID3/P00013_face3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F0005/MID1</td>\n",
       "      <td>F0005/MID2</td>\n",
       "      <td>train/F0005/MID1/P00059_face2.jpg</td>\n",
       "      <td>train/F0005/MID2/P00054_face2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F0005/MID3</td>\n",
       "      <td>F0005/MID2</td>\n",
       "      <td>train/F0005/MID3/P00059_face1.jpg</td>\n",
       "      <td>train/F0005/MID2/P00054_face2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F0009/MID1</td>\n",
       "      <td>F0009/MID4</td>\n",
       "      <td>train/F0009/MID1/P11724_face4.jpg</td>\n",
       "      <td>train/F0009/MID4/P11744_face1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p1          p2                            p1_path  \\\n",
       "0  F0002/MID1  F0002/MID3  train/F0002/MID1/P00017_face3.jpg   \n",
       "1  F0002/MID2  F0002/MID3  train/F0002/MID2/P00018_face3.jpg   \n",
       "2  F0005/MID1  F0005/MID2  train/F0005/MID1/P00059_face2.jpg   \n",
       "3  F0005/MID3  F0005/MID2  train/F0005/MID3/P00059_face1.jpg   \n",
       "4  F0009/MID1  F0009/MID4  train/F0009/MID1/P11724_face4.jpg   \n",
       "\n",
       "                             p2_path  is_related  \n",
       "0  train/F0002/MID3/P00013_face3.jpg           1  \n",
       "1  train/F0002/MID3/P00013_face3.jpg           1  \n",
       "2  train/F0005/MID2/P00054_face2.jpg           1  \n",
       "3  train/F0005/MID2/P00054_face2.jpg           1  \n",
       "4  train/F0009/MID4/P11744_face1.jpg           1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now check the train_data \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1            0\n",
       "p2            0\n",
       "p1_path       0\n",
       "p2_path       0\n",
       "is_related    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fillna(method='ffill', axis=1)\n",
    "train_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1            0\n",
       "p2            0\n",
       "p1_path       0\n",
       "p2_path       0\n",
       "is_related    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail(10)\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 224\n"
     ]
    }
   ],
   "source": [
    "#making x_train and y_train..here..........................\n",
    "\n",
    "train_image_1=[]\n",
    "train_image_2=[]\n",
    "train_label=[]\n",
    "\n",
    "h=0\n",
    "w=0\n",
    "\n",
    "for image_1,image_2,label in zip(train_data['p1_path'],train_data['p2_path'],train_data['is_related']):\n",
    "    \n",
    "        img_1=Image.open(image_1)\n",
    "        #print(image_1,image_2)\n",
    "        img_2=Image.open(image_2)\n",
    "        new1=np.array(img_1,dtype='uint8')\n",
    "        new2=np.array(img_2,dtype='uint8')\n",
    "        \n",
    "        width, height = img_1.size\n",
    "        if width>w:\n",
    "            w=width\n",
    "        if height>h:\n",
    "            h=height\n",
    "        \n",
    "        train_image_1.append(new1)\n",
    "        train_image_2.append(new2)\n",
    "        \n",
    "        train_label.append(label)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "print(h,w)\n",
    "train_image_1= np.array(train_image_1)\n",
    "train_image_2= np.array(train_image_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completed of making training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv2d_17_input (InputLayer)    (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19_input (InputLayer)    (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 224, 224, 32) 896         conv2d_17_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 224, 224, 32) 896         conv2d_19_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 112, 112, 32) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 112, 112, 32) 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 112, 112, 32) 9248        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 112, 112, 32) 9248        max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 56, 56, 32)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 56, 56, 32)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 32)   0           max_pooling2d_18[0][0]           \n",
      "                                                                 max_pooling2d_20[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 20,288\n",
      "Trainable params: 20,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model-1 structure is defining here.........................\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3))) \n",
    "model1.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model1.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model1.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "#model-2 structure is defining here..................\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3))) \n",
    "model2.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model2.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "#merging the two model................................\n",
    "mergeOut=Add()([model1.output,model2.output])\n",
    "\n",
    "mergeout=Flatten()(mergeOut)\n",
    "mergeout=Dense(256,activation='relu')(mergeout)\n",
    "mergeout=Dropout(.5)(mergeOut)\n",
    "mergeout=Dense(128,activation='relu')(mergeout)\n",
    "mergeout=Dropout(.35)(mergeOut)\n",
    "\n",
    "#output layer.......\n",
    "mergeout=Dense(2,activation='softmax')(mergeOut)\n",
    "\n",
    "newModel=Model([model1.input,model2.input],mergeOut)\n",
    "\n",
    "newModel.summary() \n",
    "\n",
    "newModel.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected add_5 to have 4 dimensions, but got array with shape (7196, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-6c892794fcc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_image_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_image_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m52\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected add_5 to have 4 dimensions, but got array with shape (7196, 1)"
     ]
    }
   ],
   "source": [
    "newModel.fit([train_image_1,train_image_2],train_label,epochs=10, batch_size=52, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
